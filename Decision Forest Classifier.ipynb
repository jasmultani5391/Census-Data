{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: is changing random_state the best way to iterate?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import TextIOWrapper\n",
    "from zipfile import ZipFile\n",
    "import io\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Files were previously uploaded from data cleaning onto Github repository.\n",
    "# Just need to pull them up with the following:\n",
    "\n",
    "feat_url = \"https://raw.githubusercontent.com/jasmultani5391/Census-Data/master/featDF.csv\"\n",
    "download1 = requests.get(feat_url).content\n",
    "\n",
    "complete_url = \"https://raw.githubusercontent.com/jasmultani5391/Census-Data/master/completeDF.csv\"\n",
    "download2 = requests.get(complete_url).content\n",
    "\n",
    "# Read the downloaded content and turn it into a pandas dataframe\n",
    "featDF = pd.read_csv(io.StringIO(download1.decode('utf-8')))\n",
    "completeDF = pd.read_csv(io.StringIO(download2.decode('utf-8')))\n",
    "\n",
    "#print(featDF.head(4))\n",
    "#print(completeDF.head(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we must find the best K index that gives us the highest\n",
    "# accuracy. We previously created a class called NearestK that contains\n",
    "# the method to search for the best K value to use. We'll use the featDF\n",
    "# over the completeDF because the former contains all the one-hot encoded\n",
    "# columns that converted qualitative to quantitative data.\n",
    "\n",
    "labelDF = featDF['salary_label']\n",
    "featDF = featDF.drop(['salary_label'],\n",
    "                     axis=1\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score %: 85.5446\n",
      "Train Precision %: 77.5862\n",
      "Train Recall %: 52.6409\n",
      "Train F1 %: 62.7244\n",
      "\n",
      "\n",
      "\n",
      "Test Accuracy Score %: 84.5493\n",
      "Test Precision %: 79.6407\n",
      "Test Recall %: 51.9024\n",
      "Test F1 %: 62.847\n",
      "maritalstatus_ Married-civ-spouse       0.172178\n",
      "relationship_ Husband                   0.156411\n",
      "norm_edunum                             0.154003\n",
      "norm_capitalgain                        0.148939\n",
      "maritalstatus_ Never-married            0.056016\n",
      "norm_age                                0.055552\n",
      "norm_hoursperweek                       0.043771\n",
      "occupation_ Exec-managerial             0.040258\n",
      "occupation_ Prof-specialty              0.034098\n",
      "norm_capitalloss                        0.026288\n",
      "relationship_ Not-in-family             0.018556\n",
      "relationship_ Wife                      0.017756\n",
      "gender_label                            0.017497\n",
      "relationship_ Own-child                 0.013268\n",
      "maritalstatus_ Divorced                 0.009518\n",
      "occupation_ Other-service               0.008812\n",
      "relationship_ Unmarried                 0.003477\n",
      "workclass_ Self-emp-inc                 0.002911\n",
      "occupation_ Machine-op-inspct           0.002420\n",
      "occupation_ Farming-fishing             0.002235\n",
      "occupation_ Handlers-cleaners           0.002060\n",
      "occupation_ Sales                       0.001763\n",
      "occupation_ Craft-repair                0.001732\n",
      "workclass_ Private                      0.001701\n",
      "workclass_ Self-emp-not-inc             0.001668\n",
      "ogcountry_label                         0.001256\n",
      "occupation_ Transport-moving            0.001037\n",
      "maritalstatus_ Widowed                  0.000924\n",
      "race_ Black                             0.000854\n",
      "occupation_ Adm-clerical                0.000741\n",
      "maritalstatus_ Separated                0.000496\n",
      "workclass_ Federal-gov                  0.000458\n",
      "race_ White                             0.000445\n",
      "relationship_ Other-relative            0.000322\n",
      "workclass_ Local-gov                    0.000299\n",
      "occupation_ Tech-support                0.000164\n",
      "occupation_ Protective-serv             0.000041\n",
      "workclass_ State-gov                    0.000036\n",
      "race_ Asian-Pac-Islander                0.000028\n",
      "maritalstatus_ Married-spouse-absent    0.000007\n",
      "occupation_ Priv-house-serv             0.000000\n",
      "race_ Amer-Indian-Eskimo                0.000000\n",
      "occupation_ Armed-Forces                0.000000\n",
      "maritalstatus_ Married-AF-spouse        0.000000\n",
      "race_ Other                             0.000000\n",
      "dtype: float64\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "trndfdata, tstdfdata, trndflbl, tstdflbl = train_test_split(featDF,\n",
    "                                                            labelDF,\n",
    "                                                            random_state=0)\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(min_samples_leaf=70,\n",
    "                                       n_estimators=150,\n",
    "                                       bootstrap=True,\n",
    "                                       oob_score=True, #use out-of-bag samples\n",
    "                                       n_jobs=-1, \n",
    "                                       random_state=0,\n",
    "                                       max_features='sqrt'\n",
    "                                      )\n",
    "\n",
    "# Fit classifier on train dataset.\n",
    "rf_classifier.fit(trndfdata, np.ravel(trndflbl))\n",
    "\n",
    "# Score based on train dataset.\n",
    "train_df_score = rf_classifier.score(trndfdata, trndflbl)\n",
    "print('Train Accuracy Score %: ' + str(round(train_df_score*100, 4)))\n",
    "\n",
    "predict_trainlabels = rf_classifier.predict(trndfdata)\n",
    "trainprecision = precision_score(trndflbl, predict_trainlabels, average='binary')\n",
    "print('Train Precision %: ' + str(round(trainprecision*100, 4)))\n",
    "            \n",
    "trainrecall = recall_score(trndflbl, predict_trainlabels, average='binary')\n",
    "print('Train Recall %: ' + str(round(trainrecall*100, 4)))\n",
    "\n",
    "trainf1 = f1_score(trndflbl, predict_trainlabels, average='binary')\n",
    "print('Train F1 %: ' + str(round(trainf1*100, 4)))\n",
    "\n",
    "\n",
    "print('\\n\\n')\n",
    "# Score based on test dataset.\n",
    "test_df_score = rf_classifier.score(tstdfdata, tstdflbl)\n",
    "print('Test Accuracy Score %: ' + str(round(test_df_score*100, 4)))\n",
    "\n",
    "predict_testlabels = rf_classifier.predict(tstdfdata)\n",
    "testprecision = precision_score(tstdflbl, predict_testlabels, average='binary')\n",
    "print('Test Precision %: ' + str(round(testprecision*100, 4)))\n",
    "            \n",
    "testrecall = recall_score(tstdflbl, predict_testlabels, average='binary')\n",
    "print('Test Recall %: ' + str(round(testrecall*100, 4)))\n",
    "\n",
    "testf1 = f1_score(tstdflbl, predict_testlabels, average='binary')\n",
    "print('Test F1 %: ' + str(round(testf1*100, 4)))\n",
    "\n",
    "\n",
    "# Most important coefficients\n",
    "important_coefficients = rf_classifier.feature_importances_\n",
    "feature_columns = list(featDF.head(0))\n",
    "importantcoef_columns = dict(zip(feature_columns, important_coefficients))\n",
    "importantcoef_series = pd.Series(importantcoef_columns)\n",
    "importantcoef_series = importantcoef_series.sort_values(ascending=False)\n",
    "importantcoef = dict(importantcoef_series)\n",
    "print(importantcoef_series)\n",
    "# Confirm we have the total number of features included, which should be 45.\n",
    "print(len(importantcoef))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
